{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_parquet('../data/processed/train.gzip')\n",
    "data_sub = pd.read_parquet('../data/processed/test.gzip')\n",
    "\n",
    "data_train.columns = [col.replace('-', '_') for col in data_train.columns]\n",
    "data_sub.columns = [col.replace('-', '_') for col in data_sub.columns]\n",
    "\n",
    "# list(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_id = data_sub[['ID']]\n",
    "\n",
    "categorical_feats = ['CO_TIPO_SEXO', 'NO_DEPARTAMENTO', 'REGION', \n",
    "                     'SALDO_PEQ_EMP_FLAG_any', 'SALDO_MED_EMP_FLAG_any', 'SALDO_MIC_EMP_FLAG_any',\n",
    "                     'CANT_EMP_NEG_FLAG_any','CANT_EMP_CONS_FLAG_any', 'CANT_EMP_HIPOT_FLAG_any',\n",
    "                     ]\n",
    "for col in categorical_feats:\n",
    "    data_train[col] = data_train[col].astype('category')\n",
    "    data_sub[col] = data_sub[col].astype('category')\n",
    "\n",
    "TARGET_VAR = 'TARGET'\n",
    "N_FOLDS = 5\n",
    "N_JOBS = int(os.cpu_count() // 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET                         int64\n",
      "ANIO_BANCARIZACION           float64\n",
      "MES_BANCARIZACION            float64\n",
      "NO_PROVINCIA                category\n",
      "REGION                      category\n",
      "                              ...   \n",
      "PROXY_MOROSIDAD_1_median     float64\n",
      "PROXY_MOROSIDAD_2_mean       float64\n",
      "PROXY_MOROSIDAD_2_median     float64\n",
      "PROXY_MOROSIDAD_3_mean       float64\n",
      "PROXY_MOROSIDAD_3_median     float64\n",
      "Length: 199, dtype: object\n"
     ]
    }
   ],
   "source": [
    "selected_cols = [\n",
    " TARGET_VAR,\n",
    " 'ANIO_BANCARIZACION', 'MES_BANCARIZACION',\n",
    " 'NO_PROVINCIA',\n",
    " 'REGION',\n",
    " 'CO_TIPO_SEXO',\n",
    " 'EDAD',\n",
    " 'NO_DEPARTAMENTO',\n",
    " 'MESES_HASTA_ACTUAL',\n",
    " 'CANT_EMP_NEG_max',\n",
    " 'CANT_EMP_NEG_last',\n",
    " 'CANT_EMP_NEG_min',\n",
    " 'CANT_EMP_CONS_max',\n",
    " 'CANT_EMP_CONS_last',\n",
    " 'CANT_EMP_CONS_min',\n",
    " 'CANT_EMP_HIPOT_max',\n",
    " 'CANT_EMP_HIPOT_last',\n",
    " 'CANT_EMP_HIPOT_min',\n",
    " 'SALDO_MED_EMP_mean',\n",
    " 'SALDO_MED_EMP_median',\n",
    " 'SALDO_MED_EMP_last',\n",
    " 'SALDO_MED_EMP_min',\n",
    " 'SALDO_MED_EMP_max',\n",
    " 'SALDO_MED_EMP_first',\n",
    " 'SALDO_PEQ_EMP_mean',\n",
    " 'SALDO_PEQ_EMP_median',\n",
    " 'SALDO_PEQ_EMP_last',\n",
    " 'SALDO_PEQ_EMP_min',\n",
    " 'SALDO_PEQ_EMP_max',\n",
    " 'SALDO_PEQ_EMP_first',\n",
    " 'SALDO_MIC_EMP_mean',\n",
    " 'SALDO_MIC_EMP_median',\n",
    " 'SALDO_MIC_EMP_last',\n",
    " 'SALDO_MIC_EMP_min',\n",
    " 'SALDO_MIC_EMP_max',\n",
    " 'SALDO_MIC_EMP_first',\n",
    " 'SALDO_CONS_REV_mean',\n",
    " 'SALDO_CONS_REV_median',\n",
    " 'SALDO_CONS_REV_last',\n",
    " 'SALDO_CONS_REV_min',\n",
    " 'SALDO_CONS_REV_max',\n",
    " 'SALDO_CONS_REV_first',\n",
    " 'SALDO_CONS_NO_REV_mean',\n",
    " 'SALDO_CONS_NO_REV_median',\n",
    " 'SALDO_CONS_NO_REV_last',\n",
    " 'SALDO_CONS_NO_REV_min',\n",
    " 'SALDO_CONS_NO_REV_max',\n",
    " 'SALDO_CONS_NO_REV_first',\n",
    " 'SALDO_HIPOT_mean',\n",
    " 'SALDO_HIPOT_median',\n",
    " 'SALDO_HIPOT_last',\n",
    " 'SALDO_HIPOT_min',\n",
    " 'SALDO_HIPOT_max',\n",
    " 'SALDO_HIPOT_first',\n",
    " 'SALDO_VENCIDO_mean',\n",
    " 'SALDO_VENCIDO_median',\n",
    " 'SALDO_VENCIDO_last',\n",
    " 'SALDO_VENCIDO_min',\n",
    " 'SALDO_VENCIDO_max',\n",
    " 'SALDO_VENCIDO_first',\n",
    " 'CANT_EMP_DOL_NEG_mean',\n",
    " 'CANT_EMP_DOL_NEG_median',\n",
    " 'CANT_EMP_DOL_NEG_last',\n",
    " 'CANT_EMP_DOL_NEG_min',\n",
    " 'CANT_EMP_DOL_NEG_max',\n",
    " 'CANT_EMP_DOL_NEG_first',\n",
    " 'SALDO_DOLA_NEG_mean',\n",
    " 'SALDO_DOLA_NEG_median',\n",
    " 'SALDO_DOLA_NEG_last',\n",
    " 'SALDO_DOLA_NEG_min',\n",
    " 'SALDO_DOLA_NEG_max',\n",
    " 'SALDO_DOLA_NEG_first',\n",
    " 'CANT_EMP_DOL_CONS_mean',\n",
    " 'CANT_EMP_DOL_CONS_median',\n",
    " 'CANT_EMP_DOL_CONS_last',\n",
    " 'CANT_EMP_DOL_CONS_min',\n",
    " 'CANT_EMP_DOL_CONS_max',\n",
    " 'CANT_EMP_DOL_CONS_first',\n",
    " 'SALDO_DOLA_CONS_mean',\n",
    " 'SALDO_DOLA_CONS_median',\n",
    " 'SALDO_DOLA_CONS_last',\n",
    " 'SALDO_DOLA_CONS_min',\n",
    " 'SALDO_DOLA_CONS_max',\n",
    " 'SALDO_DOLA_CONS_first',\n",
    " 'CANT_EMP_DOL_HIPOT_mean',\n",
    " 'CANT_EMP_DOL_HIPOT_median',\n",
    " 'CANT_EMP_DOL_HIPOT_last',\n",
    " 'CANT_EMP_DOL_HIPOT_min',\n",
    " 'CANT_EMP_DOL_HIPOT_max',\n",
    " 'CANT_EMP_DOL_HIPOT_first',\n",
    " 'SALDO_DOLA_HIPOT_mean',\n",
    " 'SALDO_DOLA_HIPOT_median',\n",
    " 'SALDO_DOLA_HIPOT_last',\n",
    " 'SALDO_DOLA_HIPOT_min',\n",
    " 'SALDO_DOLA_HIPOT_max',\n",
    " 'SALDO_DOLA_HIPOT_first',\n",
    " 'MAX_LINEA_DISP_U6M_mean',\n",
    " 'MAX_LINEA_DISP_U6M_median',\n",
    " 'MAX_LINEA_DISP_U6M_last',\n",
    " 'MAX_LINEA_DISP_U6M_min',\n",
    " 'MAX_LINEA_DISP_U6M_max',\n",
    " 'MAX_LINEA_DISP_U6M_first',\n",
    " 'SALDO_EMP_TOTAL_mean',\n",
    " 'SALDO_EMP_TOTAL_last',\n",
    " 'SALDO_EMP_TOTAL_max',\n",
    " 'SALDO_EMP_TOTAL_min',\n",
    " 'SALDO_EMP_TOTAL_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_1_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_1_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA3_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA3_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA6_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA6_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA8_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_MA8_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_1_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_1_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA3_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA3_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA6_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA6_median',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA8_mean',\n",
    " 'VAR_SALDO_EMP_TOTAL_VENCIDO_MA8_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_1_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_1_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA3_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA3_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA6_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA6_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA8_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_MA8_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_1_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_1_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA3_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA3_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA6_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA6_median',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA8_mean',\n",
    " 'DIFF_SALDO_EMP_TOTAL_VENCIDO_MA8_median',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_1_mean',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_1_median',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA3_mean',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA3_median',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA6_mean',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA6_median',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA8_mean',\n",
    " 'DIFF_MAX_LINEA_DISP_U6M_MA8_median',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_1_mean',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_1_median',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA3_mean',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA3_median',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA6_mean',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA6_median',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA8_mean',\n",
    " 'VAR_SALDO_REV_NO_REV_VENCIDO_MA8_median',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_1_mean',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_1_median',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA3_mean',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA3_median',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA6_mean',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA6_median',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA8_mean',\n",
    " 'VAR_SALDO_TOTAL_VENCIDO_MA8_median',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_1_mean',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_1_median',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA3_mean',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA3_median',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA6_mean',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA6_median',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA8_mean',\n",
    " 'VAR_MAX_LINEA_DISP_U6M_MA8_median',\n",
    " 'VAR_SALDO_DOLA_TOTAL_1_mean',\n",
    " 'VAR_SALDO_DOLA_TOTAL_1_median',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA3_mean',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA3_median',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA6_mean',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA6_median',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA8_mean',\n",
    " 'VAR_SALDO_DOLA_TOTAL_MA8_median',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_1_mean',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_1_median',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA3_mean',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA3_median',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA6_mean',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA6_median',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA8_mean',\n",
    " 'DIFF_SALDO_DOLA_TOTAL_MA8_median',\n",
    " 'SALDO_PEQ_EMP_FLAG_any',\n",
    " 'SALDO_MED_EMP_FLAG_any',\n",
    " 'SALDO_MIC_EMP_FLAG_any',\n",
    " 'CANT_EMP_NEG_FLAG_any',\n",
    " 'CANT_EMP_CONS_FLAG_any',\n",
    " 'CANT_EMP_HIPOT_FLAG_any',\n",
    " 'PROXY_MOROSIDAD_1_mean',\n",
    " 'PROXY_MOROSIDAD_1_median',\n",
    " 'PROXY_MOROSIDAD_2_mean',\n",
    " 'PROXY_MOROSIDAD_2_median',\n",
    " 'PROXY_MOROSIDAD_3_mean',\n",
    " 'PROXY_MOROSIDAD_3_median',\n",
    "]\n",
    "\n",
    "data_train =  data_train.select_dtypes(include=['int64', 'float64', 'category'])\n",
    "data_train = data_train[selected_cols]\n",
    "\n",
    "data_sub = data_sub.select_dtypes(include=['int64', 'float64', 'category'])\n",
    "data_sub = data_sub[selected_cols]\n",
    "\n",
    "list(data_train.columns)\n",
    "print(data_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.849992\n",
       "1   0.150008\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[TARGET_VAR].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgboost_model():\n",
    "    return xgb.XGBClassifier(\n",
    "        n_estimators=200, \n",
    "        max_depth=8, \n",
    "        learning_rate=0.1, \n",
    "        objective='binary:logistic', \n",
    "        booster='gbtree', \n",
    "        tree_method='auto', \n",
    "        n_jobs=-1, \n",
    "        verbosity=0, \n",
    "        enable_categorical=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def get_catboost_model(cat_features):\n",
    "    return CatBoostClassifier(\n",
    "        iterations=200, \n",
    "        depth=8, \n",
    "        learning_rate=0.1, \n",
    "        loss_function='Logloss', \n",
    "        eval_metric='F1', \n",
    "        random_seed=42, \n",
    "        verbose=0, \n",
    "        cat_features=cat_features,\n",
    "        thread_count=N_JOBS, \n",
    "        task_type='GPU', \n",
    "        devices='0:1'\n",
    "    )\n",
    "\n",
    "\n",
    "def get_lgbm_model():\n",
    "    return lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', \n",
    "        num_leaves=31, \n",
    "        max_depth=-1, \n",
    "        learning_rate=0.1, \n",
    "        n_estimators=200, \n",
    "        objective='binary', \n",
    "        min_split_gain=0.0, \n",
    "        min_child_weight=0.001, \n",
    "        min_child_samples=20, \n",
    "        subsample=1.0, \n",
    "        subsample_freq=0, \n",
    "        colsample_bytree=1.0, \n",
    "        reg_alpha=0.0, \n",
    "        reg_lambda=0.0, \n",
    "        random_state=42, \n",
    "        n_jobs=N_JOBS,\n",
    "        importance_type='split',\n",
    "    )\n",
    "\n",
    "def get_random_forest_model():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=200, \n",
    "        max_depth=8, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1, \n",
    "        min_weight_fraction_leaf=0.0, \n",
    "        max_features='auto', \n",
    "        max_leaf_nodes=None, \n",
    "        min_impurity_decrease=0.0, \n",
    "        bootstrap=True, \n",
    "        oob_score=False, \n",
    "        n_jobs=N_JOBS, \n",
    "        random_state=42, \n",
    "        verbose=0, \n",
    "        warm_start=False, \n",
    "        class_weight=None, \n",
    "        ccp_alpha=0.0, \n",
    "        max_samples=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy={0: 70000}, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(data_train.drop(TARGET_VAR, axis=1), data_train[TARGET_VAR])\n",
    "\n",
    "data_train_resampled = pd.concat([X_resampled, y_resampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data_train.copy()\n",
    "\n",
    "X = data_train_resampled.drop(columns=[TARGET_VAR])\n",
    "y = data_train_resampled[TARGET_VAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9575, number of negative: 48999\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36927\n",
      "[LightGBM] [Info] Number of data points in the train set: 58574, number of used features: 196\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.163468 -> initscore=-1.632644\n",
      "[LightGBM] [Info] Start training from score -1.632644\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "cat_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "X_train[cat_features] = X_train[cat_features].astype('category')\n",
    "X_test[cat_features] = X_test[cat_features].astype('category')\n",
    "\n",
    "\n",
    "# generate ensemble of models\n",
    "models = []\n",
    "models.append(('XGB', get_xgboost_model()))\n",
    "models.append(('CAT', get_catboost_model(cat_features)))\n",
    "models.append(('LGBM', get_lgbm_model()))\n",
    "models.append(('RF', get_random_forest_model()))\n",
    "\n",
    "for name, model in models:\n",
    "    if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "        model.fit(X_train, y_train, verbose=0)\n",
    "    elif model.__class__.__name__ == 'LGBMClassifier':\n",
    "        model.fit(X_train, y_train, categorical_feature=cat_features)\n",
    "    elif model.__class__.__name__ == 'XGBClassifier':\n",
    "        model.fit(X_train, y_train, verbose=0)\n",
    "    elif model.__class__.__name__ == 'RandomForestClassifier':\n",
    "        # perform one hot encoding\n",
    "        X_train_aux = pd.get_dummies(X_train, drop_first=True)\n",
    "        \n",
    "        model.fit(X_train_aux, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     48999\n",
      "           1       0.70      0.66      0.68      9575\n",
      "\n",
      "    accuracy                           0.90     58574\n",
      "   macro avg       0.82      0.80      0.81     58574\n",
      "weighted avg       0.90      0.90      0.90     58574\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     21001\n",
      "           1       0.59      0.52      0.55      4103\n",
      "\n",
      "    accuracy                           0.86     25104\n",
      "   macro avg       0.75      0.72      0.73     25104\n",
      "weighted avg       0.86      0.86      0.86     25104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_predictions_train = pd.DataFrame()\n",
    "\n",
    "FACTOR = 0.3\n",
    "selected_models = ['CAT', 'LGBM']  # 'XGB', 'RF'\n",
    "\n",
    "for name, model in models:\n",
    "    if name not in selected_models:\n",
    "        continue\n",
    "    model_name = model.__class__.__name__\n",
    "    if model_name == 'RandomForestClassifier':\n",
    "        X_train_aux = pd.get_dummies(X_train, drop_first=True)\n",
    "        stacked_predictions_train[f'{model_name}_train'] = model.predict_proba(X_train_aux)[:, 1]\n",
    "    else:\n",
    "        stacked_predictions_train[f'{model_name}_train'] = model.predict_proba(X_train)[:, 1]\n",
    "stacked_predictions_train['TRAIN'] = stacked_predictions_train.mean(axis=1)\n",
    "stacked_predictions_train['TRAIN'] = np.where(stacked_predictions_train['TRAIN'] > FACTOR, 1, 0)\n",
    "print('TRAIN')\n",
    "print(classification_report(y_train, stacked_predictions_train['TRAIN']))\n",
    "\n",
    "stacked_predictions_test = pd.DataFrame()\n",
    "\n",
    "for name, model in models:\n",
    "    if name not in selected_models:\n",
    "        continue\n",
    "    model_name = model.__class__.__name__\n",
    "    if model_name == 'RandomForestClassifier':\n",
    "        X_test_aux = pd.get_dummies(X_test, drop_first=True)\n",
    "        stacked_predictions_test[f'{model_name}_test'] = model.predict_proba(X_test_aux)[:, 1]\n",
    "    else:\n",
    "        stacked_predictions_test[f'{model_name}_test'] = model.predict_proba(X_test)[:, 1]\n",
    "stacked_predictions_test['TEST'] = stacked_predictions_test.mean(axis=1)\n",
    "stacked_predictions_test['TEST'] = np.where(stacked_predictions_test['TEST'] > FACTOR, 1, 0)\n",
    "print('TEST')\n",
    "print(classification_report(y_test, stacked_predictions_test['TEST']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     56000\n",
      "           1       0.66      0.60      0.63     10942\n",
      "\n",
      "    accuracy                           0.88     66942\n",
      "   macro avg       0.79      0.77      0.78     66942\n",
      "weighted avg       0.88      0.88      0.88     66942\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     14000\n",
      "           1       0.59      0.51      0.55      2736\n",
      "\n",
      "    accuracy                           0.86     16736\n",
      "   macro avg       0.75      0.72      0.73     16736\n",
      "weighted avg       0.85      0.86      0.86     16736\n",
      "\n",
      "F1 macro score\n",
      "0.7327331522040901\n",
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     56000\n",
      "           1       0.66      0.61      0.63     10942\n",
      "\n",
      "    accuracy                           0.89     66942\n",
      "   macro avg       0.79      0.77      0.78     66942\n",
      "weighted avg       0.88      0.89      0.88     66942\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     14000\n",
      "           1       0.58      0.51      0.54      2736\n",
      "\n",
      "    accuracy                           0.86     16736\n",
      "   macro avg       0.74      0.72      0.73     16736\n",
      "weighted avg       0.85      0.86      0.86     16736\n",
      "\n",
      "F1 macro score\n",
      "0.7294819566999796\n",
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     56000\n",
      "           1       0.66      0.61      0.63     10942\n",
      "\n",
      "    accuracy                           0.89     66942\n",
      "   macro avg       0.79      0.77      0.78     66942\n",
      "weighted avg       0.88      0.89      0.88     66942\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     14000\n",
      "           1       0.57      0.53      0.55      2736\n",
      "\n",
      "    accuracy                           0.86     16736\n",
      "   macro avg       0.74      0.73      0.73     16736\n",
      "weighted avg       0.86      0.86      0.86     16736\n",
      "\n",
      "F1 macro score\n",
      "0.7347823373045341\n",
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     56000\n",
      "           1       0.67      0.60      0.63     10943\n",
      "\n",
      "    accuracy                           0.89     66943\n",
      "   macro avg       0.80      0.77      0.78     66943\n",
      "weighted avg       0.88      0.89      0.88     66943\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     14000\n",
      "           1       0.58      0.54      0.56      2735\n",
      "\n",
      "    accuracy                           0.86     16735\n",
      "   macro avg       0.74      0.73      0.74     16735\n",
      "weighted avg       0.86      0.86      0.86     16735\n",
      "\n",
      "F1 macro score\n",
      "0.7372547114958918\n",
      "TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     56000\n",
      "           1       0.66      0.60      0.63     10943\n",
      "\n",
      "    accuracy                           0.89     66943\n",
      "   macro avg       0.79      0.77      0.78     66943\n",
      "weighted avg       0.88      0.89      0.88     66943\n",
      "\n",
      "TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     14000\n",
      "           1       0.58      0.53      0.56      2735\n",
      "\n",
      "    accuracy                           0.86     16735\n",
      "   macro avg       0.75      0.73      0.74     16735\n",
      "weighted avg       0.86      0.86      0.86     16735\n",
      "\n",
      "F1 macro score\n",
      "0.7375980246497229\n",
      "F1 macro mean: 0.7343700364708436\n"
     ]
    }
   ],
   "source": [
    "# perform stratified k-fold cross validation\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "f1_macros = []\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    models = []\n",
    "    # models.append(('XGB', get_xgboost_model()))\n",
    "    models.append(('CAT', get_catboost_model(cat_features)))\n",
    "    # models.append(('LGBM', get_lgbm_model()))\n",
    "    models.append(('RF', get_random_forest_model()))\n",
    "\n",
    "    for name, model in models:\n",
    "        if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "            model.fit(X_train, y_train, verbose=0)\n",
    "        elif model.__class__.__name__ == 'LGBMClassifier':\n",
    "            model.fit(X_train, y_train, categorical_feature=cat_features)\n",
    "        elif model.__class__.__name__ == 'XGBClassifier':\n",
    "            model.fit(X_train, y_train, verbose=0)\n",
    "        elif model.__class__.__name__ == 'RandomForestClassifier':\n",
    "            # perform one hot encoding\n",
    "            X_train_aux = pd.get_dummies(X_train, drop_first=True)\n",
    "            \n",
    "            model.fit(X_train_aux, y_train)\n",
    "    \n",
    "    stacked_predictions_train = pd.DataFrame()\n",
    "\n",
    "    FACTOR = 0.3\n",
    "    selected_models = ['CAT', 'LGBM']  # , 'LGBM',  \n",
    "\n",
    "    for name, model in models:\n",
    "        if name not in selected_models:\n",
    "            continue\n",
    "        model_name = model.__class__.__name__\n",
    "        if model_name == 'RandomForestClassifier':\n",
    "            X_train_aux = pd.get_dummies(X_train)\n",
    "            stacked_predictions_train[f'{model_name}_train'] = model.predict_proba(X_train_aux)[:, 1]\n",
    "        else:\n",
    "            stacked_predictions_train[f'{model_name}_train'] = model.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    stacked_predictions_train['TRAIN'] = stacked_predictions_train.mean(axis=1)\n",
    "    stacked_predictions_train['TRAIN'] = np.where(stacked_predictions_train['TRAIN'] > FACTOR, 1, 0)\n",
    "\n",
    "    print('TRAIN')\n",
    "    print(classification_report(y_train, stacked_predictions_train['TRAIN']))\n",
    "\n",
    "    stacked_predictions_test = pd.DataFrame()\n",
    "\n",
    "    for name, model in models:\n",
    "        if name not in selected_models:\n",
    "            continue\n",
    "        model_name = model.__class__.__name__\n",
    "        if model_name == 'RandomForestClassifier':\n",
    "            X_test_aux = pd.get_dummies(X_test, drop_first=True)\n",
    "            stacked_predictions_test[f'{model_name}_test'] = model.predict_proba(X_test_aux)[:, 1]\n",
    "        else:\n",
    "            stacked_predictions_test[f'{model_name}_test'] = model.predict_proba(X_test)[:, 1]\n",
    "    stacked_predictions_test['TEST'] = stacked_predictions_test.mean(axis=1)\n",
    "    stacked_predictions_test['TEST'] = np.where(stacked_predictions_test['TEST'] > FACTOR, 1, 0)\n",
    "    print('TEST')\n",
    "    print(classification_report(y_test, stacked_predictions_test['TEST']))\n",
    "\n",
    "    # calculate f1 macro score\n",
    "    print('F1 macro score')\n",
    "    print(f1_score(y_test, stacked_predictions_test['TEST'], average='macro'))\n",
    "\n",
    "    f1_macros.append(f1_score(y_test, stacked_predictions_test['TEST'], average='macro'))\n",
    "    \n",
    "print(f'F1 macro mean: {np.mean(f1_macros)}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
